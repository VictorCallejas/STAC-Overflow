{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd \r\n",
    "import numpy as np \r\n",
    "\r\n",
    "import neptune.new as neptune\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm \r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "import torchvision.transforms as T\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metadata = pd.read_csv( \"../data/raw/metadata.csv\", parse_dates=[\"scene_start\"])\r\n",
    "print(metadata.shape)\r\n",
    "metadata.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metadata.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CALCULATE DATASET NORMALIZATION\r\n",
    "# RESULTS \r\n",
    "# VV -10.4163 4.0595093\r\n",
    "# VH -17.3540 4.3767033\r\n",
    "\r\n",
    "def masked_std(x, mask):\r\n",
    "    mask = np.repeat(np.expand_dims(mask > 0, axis = 0), 3,axis=0).reshape(3,-1)\r\n",
    "    return np.std(np.transpose(x,[1,0,2,3]).reshape(3,-1),axis=1,where=mask)\r\n",
    "\r\n",
    "def masked_mean(x, mask):\r\n",
    "    mask = np.repeat(np.expand_dims(mask > 0, axis = 0), 3,axis=0).reshape(3,-1)\r\n",
    "    return np.mean(np.transpose(x,[1,0,2,3]).reshape(3,-1),axis=1,where=mask)\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "loader = DataLoader(train_dataset, batch_size=len(train_dataset), num_workers=0)\r\n",
    "data = next(iter(loader))\r\n",
    "\r\n",
    "print(masked_mean(data['x'],data['mask'],0), masked_std(data['x'],data['mask'],0))\r\n",
    "print(masked_mean(data['x'],data['mask'],1), masked_std(data['x'],data['mask'],1))\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import rasterio\r\n",
    "from torch.utils.data import Dataset\r\n",
    "import albumentations as A \r\n",
    "\r\n",
    "DATA_PATH = '../data/raw/'\r\n",
    "CHANNELS = ['_vv','_vh']\r\n",
    "EXT = '.tif'\r\n",
    "\r\n",
    "DTYPE = torch.float32\r\n",
    "MEM_DTYPE = np.float32\r\n",
    "\r\n",
    "X_NAN_VALUE = -255\r\n",
    "Y_NAN_VALUE = 255\r\n",
    "\r\n",
    "TEST_AUGMENTATIONS = [\r\n",
    "    A.Transpose(p=1),\r\n",
    "    A.VerticalFlip(p=1),\r\n",
    "    A.HorizontalFlip(p=1),\r\n",
    "]\r\n",
    "\r\n",
    "TRAIN_AUGMENTATIONS = [\r\n",
    "    A.Transpose(p=1),\r\n",
    "    A.VerticalFlip(p=1),\r\n",
    "    A.HorizontalFlip(p=1),\r\n",
    "]\r\n",
    "\r\n",
    "class IterChip(Dataset):\r\n",
    "\r\n",
    "    def __init__(self,chip_ids,augment = True):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.chip_ids = chip_ids\r\n",
    "\r\n",
    "        self.augment = augment\r\n",
    "        self.TRAIN_AUGMENTATIONS = TRAIN_AUGMENTATIONS\r\n",
    "\r\n",
    "        self.TEST_AUGMENTATIONS = TEST_AUGMENTATIONS\r\n",
    "        \r\n",
    "        self.ABS_CHANNEL = True\r\n",
    "\r\n",
    "        self.x = []\r\n",
    "        self.mask = []\r\n",
    "        self.y = []\r\n",
    "\r\n",
    "        print('creating dataset')\r\n",
    "        print('reading chips')\r\n",
    "        for id_ in tqdm(self.chip_ids):\r\n",
    "            # VV, VH\r\n",
    "            path = DATA_PATH + '/images/' + id_ + '_vv' + EXT\r\n",
    "            with rasterio.open(path) as img:\r\n",
    "                vv = img.read(1)\r\n",
    "            path = DATA_PATH + '/images/' + id_ + '_vh' + EXT\r\n",
    "            with rasterio.open(path) as img:\r\n",
    "                vh = img.read(1)\r\n",
    "\r\n",
    "            x_ = np.stack([vv, vh], axis=0)\r\n",
    "\r\n",
    "            if self.ABS_CHANNEL:\r\n",
    "                va = np.abs(np.diff(x_,axis=0))\r\n",
    "                x_ = np.concatenate([x_, va], axis=0)\r\n",
    "            \r\n",
    "            self.x.append(x_)\r\n",
    "\r\n",
    "            # MASK\r\n",
    "            path = DATA_PATH + '/images/' + id_ + '_vv'  + EXT\r\n",
    "            with rasterio.open(path) as img:\r\n",
    "                mask_ = img.dataset_mask() / 255\r\n",
    "                self.mask.append(mask_)\r\n",
    "\r\n",
    "            #LABEL\r\n",
    "            path = DATA_PATH + '/labels/' + id_  + EXT\r\n",
    "            with rasterio.open(path) as img:\r\n",
    "                y_ = img.read(1)\r\n",
    "            self.y.append(y_)\r\n",
    "\r\n",
    "        self.x = np.array(self.x,dtype=MEM_DTYPE)\r\n",
    "        self.mask = np.array(self.mask,dtype=MEM_DTYPE)\r\n",
    "        self.y = np.array(self.y,dtype=MEM_DTYPE)\r\n",
    "\r\n",
    "        print('calculating norms - mean and std')\r\n",
    "        self.t_mean = masked_mean(self.x,self.mask)\r\n",
    "        self.t_std = masked_std(self.x,self.mask)\r\n",
    "\r\n",
    "        # VV -10.4163 4.0595093\r\n",
    "        # VH -17.3540 4.3767033\r\n",
    "        print('NORMALIZE: ', self.t_mean, self.t_std)\r\n",
    "        print('normalizing...')\r\n",
    "        for dim, _p in enumerate(zip(self.t_mean, self.t_std)):\r\n",
    "            _mean, _std = _p\r\n",
    "            self.x[:,dim] = (self.x[:,dim] - _mean) / _std\r\n",
    "\r\n",
    "        print('DATASET CREATED', self.x.shape)\r\n",
    "\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.chip_ids)\r\n",
    "\r\n",
    "    def __getitem__(self, index, test_augment=False):\r\n",
    "\r\n",
    "        x_ = np.expand_dims(self.x[index],axis=0)\r\n",
    "        y_ = np.expand_dims(self.y[index],axis=0)\r\n",
    "\r\n",
    "        # Train Augments\r\n",
    "        if self.augment:\r\n",
    "\r\n",
    "            _ax, _ay = np.array([]).reshape(0,3,512,512), np.array([]).reshape(0,512,512)\r\n",
    "\r\n",
    "            for k in [2]:\r\n",
    "\r\n",
    "                _x = np.rot90(x_,k=k,axes=(2,3))\r\n",
    "                _y = np.rot90(y_,k=k,axes=(1,2))\r\n",
    "\r\n",
    "                _ax = np.concatenate([_ax, _x],axis=0)\r\n",
    "                _ay = np.concatenate([_ay, _y],axis=0)\r\n",
    "            \r\n",
    "            x_ = np.concatenate([x_, _ax], axis=0)\r\n",
    "            y_ = np.concatenate([y_, _ay], axis=0)\r\n",
    "\r\n",
    "        # Test Augments\r\n",
    "        if test_augment:\r\n",
    "            for augmentation in self.TEST_AUGMENTATIONS:\r\n",
    "\r\n",
    "                aug = A.Compose([\r\n",
    "                    augmentation\r\n",
    "                ])\r\n",
    "\r\n",
    "                x_ = np.transpose(x_, [1, 2, 0])\r\n",
    "\r\n",
    "        #x[0][y == Y_NAN_VALUE] = X_NAN_VALUE\r\n",
    "        #x[1][y == Y_NAN_VALUE] = X_NAN_VALUE\r\n",
    "\r\n",
    "        x_ = torch.tensor(x_).to(DTYPE)\r\n",
    "        y_ = torch.tensor(y_).to(DTYPE)\r\n",
    "\r\n",
    "        return {\r\n",
    "            'x':x_,\r\n",
    "            #'mask':mask,\r\n",
    "            'label':y_\r\n",
    "        }\r\n",
    "\r\n",
    "    def converge_aug_inference(self, preds):\r\n",
    "        \r\n",
    "        y = np.transpose(preds.unsqueeze(1).numpy(), [0, 2, 3, 1])\r\n",
    "\r\n",
    "        p = np.expand_dims(y[0], axis=0)\r\n",
    "        y = y[1:]\r\n",
    "\r\n",
    "        for augmentation, y_ in zip(self.TEST_AUGMENTATIONS, y):\r\n",
    "\r\n",
    "            aug = A.Compose([\r\n",
    "                augmentation\r\n",
    "            ])\r\n",
    "\r\n",
    "            transformed = aug(image=y_)\r\n",
    "\r\n",
    "            p = np.concatenate((p, np.expand_dims(transformed['image'], axis=0)))\r\n",
    "        \r\n",
    "        p = np.transpose(p, [0, 3, 1, 2]).squeeze(1)\r\n",
    "        p = np.mean(p,axis=0)\r\n",
    "        \r\n",
    "        p = torch.tensor(p).to(DTYPE).unsqueeze(0)\r\n",
    "\r\n",
    "        return p"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#542\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "train, val = train_test_split(metadata.chip_id, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "train_dataset = IterChip(train,True)\r\n",
    "val_dataset = IterChip(val,False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n",
    "\r\n",
    "BS = 3\r\n",
    "NW = 0\r\n",
    "\r\n",
    "train_dataloader = DataLoader(\r\n",
    "    dataset=train_dataset,\r\n",
    "    sampler=RandomSampler(train_dataset),\r\n",
    "    batch_size=BS,\r\n",
    "    num_workers=NW,\r\n",
    "    pin_memory=True\r\n",
    ")\r\n",
    "\r\n",
    "val_dataloader = DataLoader(\r\n",
    "    dataset=val_dataset,\r\n",
    "    sampler=SequentialSampler(val_dataset),\r\n",
    "    batch_size=BS,\r\n",
    "    num_workers=NW,\r\n",
    "    pin_memory=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\r\n",
    "sys.path.append('..')\r\n",
    "from src.models.swin_unet import SwinTransformerSys\r\n",
    "import segmentation_models_pytorch as smp\r\n",
    "from src.models.repvgg.repvgg import repvgg_model_convert, create_RepVGG_A0\r\n",
    "from src.models.brr import BRR\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "model = SwinTransformerSys(img_size=512, patch_size=4, in_chans=3, num_classes=1,\r\n",
    "            embed_dim=96, depths=[2, 2, 2, 2], depths_decoder=[2, 2, 2, 2], num_heads=[4, 4, 4, 4],\r\n",
    "            window_size=8, mlp_ratio=4., qkv_bias=True, qk_scale=None,\r\n",
    "            drop_rate=0., attn_drop_rate=0., drop_path_rate=0.0,\r\n",
    "            norm_layer=nn.LayerNorm, ape=True, patch_norm=True,\r\n",
    "            use_checkpoint=False, final_upsample=\"expand_first\")\r\n",
    "\r\n",
    "torch.backends.cudnn.benchmark = True\r\n",
    "\"\"\"\r\n",
    "model = smp.Unet(\r\n",
    "    encoder_name=\"resnext50_32x4d\",       \r\n",
    "    encoder_weights=\"imagenet\", \r\n",
    "    in_channels=2,                  \r\n",
    "    classes=1,                      \r\n",
    ")\r\n",
    "\r\n",
    "#model = BRR()\r\n",
    "\r\n",
    "#model = create_RepVGG_A0(deploy=False)\r\n",
    "#model = nn.Conv2d(2,1,(7,7),stride=(1,1),padding=3)\r\n",
    "#model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=2, out_channels=1, init_features=64, pretrained=False)\r\n",
    "\r\n",
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run = neptune.init(\r\n",
    "    project='victorcallejas/FBSim',\r\n",
    "    api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlNDRlNTJiNC00OTQwLTQxYjgtYWZiNS02OWQ0MDcwZmU5N2YifQ=='\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\")\r\n",
    "device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from segmentation_models_pytorch.losses.soft_bce import SoftBCEWithLogitsLoss\r\n",
    "from segmentation_models_pytorch.losses import DiceLoss, LovaszLoss\r\n",
    "\r\n",
    "def jaccard_coeff(preds, true):\r\n",
    "\r\n",
    "    preds = nn.Sigmoid()(preds)\r\n",
    "    preds = (preds > 0.5) * 1\r\n",
    "\r\n",
    "    valid_pixel_mask = true.ne(255)\r\n",
    "    true = true.masked_select(valid_pixel_mask)\r\n",
    "    preds = preds.masked_select(valid_pixel_mask)\r\n",
    "\r\n",
    "    intersection = np.logical_and(true, preds)\r\n",
    "    union = np.logical_or(true, preds)\r\n",
    "    return intersection.sum() / union.sum()\r\n",
    "\r\n",
    "def BCE1_DICE(preds, true):\r\n",
    "    #f(x) = BCE + 1 — DICE\r\n",
    "    bce = SoftBCEWithLogitsLoss(ignore_index = Y_NAN_VALUE,smooth_factor = 0.05)\r\n",
    "    dice = DiceLoss('binary', log_loss=True, from_logits=True, smooth=0.05, ignore_index=Y_NAN_VALUE, eps=1e-07)\r\n",
    "    return 0.5 * bce(preds,true) + 0.5 * dice(preds,true)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = torch.optim.AdamW(\r\n",
    "                model.parameters(),\r\n",
    "                lr = 5e-4\r\n",
    "            )\r\n",
    "\r\n",
    "criterion = BCE1_DICE\r\n",
    "#criterion = SoftBCEWithLogitsLoss(ignore_index = Y_NAN_VALUE,smooth_factor = 0.1).to(device)\r\n",
    "#criterion = DiceLoss('binary', log_loss=False, from_logits=True, smooth=0.2, ignore_index=Y_NAN_VALUE, eps=1e-07)\r\n",
    "#criterion = LovaszLoss('binary',from_logits=True,ignore_index=Y_NAN_VALUE).to(device)\r\n",
    "#jaccard = JaccardLoss(from_logits = True, mode = 'binary')\r\n",
    "\r\n",
    "fp16 = False\r\n",
    "scaler = torch.cuda.amp.GradScaler()\r\n",
    "\r\n",
    "iters_to_accumulate = 2\r\n",
    "\r\n",
    "VAL_WATERSHED = False\r\n",
    "VAL_PLOT =True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from src.utils.plot import display_preds\r\n",
    "%matplotlib agg\r\n",
    "\r\n",
    "from src.utils.post import post_watershed\r\n",
    "\r\n",
    "def valid(model,val_dataloader, plot = True, watershed = False):\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    labels, preds = torch.tensor([]), torch.tensor([])\r\n",
    "\r\n",
    "    for _, batch in tqdm(enumerate(val_dataloader),total=len(val_dataloader),leave=False):\r\n",
    "\r\n",
    "        x = batch['x'].to(device,non_blocking=True).flatten(0,1)\r\n",
    "        targets = batch['label'].to(device,non_blocking=True).flatten(0,1)\r\n",
    "        \r\n",
    "        with torch.cuda.amp.autocast(enabled=fp16):\r\n",
    "            with torch.no_grad(): \r\n",
    "                b_preds = model(x).squeeze(1)\r\n",
    "                loss = criterion(b_preds, targets)\r\n",
    "        \r\n",
    "                scaler.scale(loss)\r\n",
    "                run[\"dev/batch_loss\"].log(loss.item())\r\n",
    "\r\n",
    "                preds = torch.cat([preds, b_preds.detach().cpu()], dim = 0)\r\n",
    "                labels = torch.cat([labels, targets.detach().cpu()], dim = 0)\r\n",
    "                 \r\n",
    "\r\n",
    "    epoch_loss = criterion(preds,labels)\r\n",
    "    run[\"dev/loss\"].log(epoch_loss)\r\n",
    "\r\n",
    "    jac = jaccard_coeff(preds,labels)\r\n",
    "    run[\"dev/jaccard\"].log(jac)\r\n",
    "\r\n",
    "    if watershed:\r\n",
    "        preds_ws = post_watershed(preds)\r\n",
    "        jac_w = jaccard_coeff(preds_ws,labels)\r\n",
    "        run[\"dev/jaccard_ws\"].log(jac_w)\r\n",
    "\r\n",
    "    print('Validation: ', epoch_loss, jac)\r\n",
    "\r\n",
    "    if plot:\r\n",
    "        fig = display_preds(val_dataset ,preds,labels,2)\r\n",
    "        run['validation/plt'].upload(fig)\r\n",
    "\r\n",
    "                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = model.to(device)\r\n",
    "\r\n",
    "steps = 0\r\n",
    "\r\n",
    "for epoch in tqdm(range(1,1000)):\r\n",
    "\r\n",
    "    print('Epoch: ',epoch)\r\n",
    "\r\n",
    "    model.train()\r\n",
    "    optimizer.zero_grad(set_to_none=True)\r\n",
    "\r\n",
    "    labels, preds = torch.tensor([]), torch.tensor([])\r\n",
    "\r\n",
    "    for step, batch in tqdm(enumerate(train_dataloader),total=len(train_dataloader),leave=False):\r\n",
    "\r\n",
    "        x = batch['x'].to(device,non_blocking=True)\r\n",
    "        targets = batch['label'].to(device,non_blocking=True)\r\n",
    "        \r\n",
    "        with torch.cuda.amp.autocast(enabled=fp16):\r\n",
    "            b_preds = model(x).squeeze(1)\r\n",
    "            loss = criterion(b_preds, targets)\r\n",
    "        scaler.scale(loss).backward()\r\n",
    "\r\n",
    "        run[\"train/batch_loss\"].log(loss.item())\r\n",
    "\r\n",
    "        if (step + 1) % iters_to_accumulate == 0:\r\n",
    "            scaler.unscale_(optimizer)\r\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),5.0)\r\n",
    "\r\n",
    "            scaler.step(optimizer)\r\n",
    "            scaler.update()\r\n",
    "            optimizer.zero_grad(set_to_none=True)\r\n",
    "\r\n",
    "        preds = torch.cat([preds, b_preds.detach().cpu()], dim = 0)\r\n",
    "        labels = torch.cat([labels, targets.detach().cpu()], dim = 0)   \r\n",
    "\r\n",
    "    epoch_loss = criterion(preds,labels)\r\n",
    "    run[\"train/loss\"].log(epoch_loss)\r\n",
    "\r\n",
    "    jac = jaccard_coeff(preds,labels)\r\n",
    "    run[\"train/jaccard\"].log(jac)\r\n",
    "\r\n",
    "    print('Train: ', epoch_loss, jac)\r\n",
    "    valid(model,val_dataloader,VAL_PLOT, VAL_WATERSHED)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(model,'../artifacts/model.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = torch.load('../artifacts/model.pt',map_location=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AUGMENTED INFERENCE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_aug_dataset = IterChip(val,False,True)\r\n",
    "\r\n",
    "val_aug_dataloader = DataLoader(\r\n",
    "    val_aug_dataset,\r\n",
    "    sampler = SequentialSampler(val_aug_dataset),\r\n",
    "    batch_size=1,\r\n",
    "    pin_memory=True,\r\n",
    "    num_workers=NW\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.eval()\r\n",
    "\r\n",
    "labels, preds = torch.tensor([]), torch.tensor([])\r\n",
    "\r\n",
    "for _, batch in tqdm(enumerate(val_aug_dataloader),total=len(val_aug_dataloader),leave=False):\r\n",
    "\r\n",
    "    x = batch['x'].to(device,non_blocking=True).squeeze(0) # BATCH SIZE ALWAYS MAKE 1\r\n",
    "    targets = batch['label'][0][0].unsqueeze(0)\r\n",
    "   \r\n",
    "    with torch.cuda.amp.autocast(enabled=fp16):\r\n",
    "        with torch.no_grad(): \r\n",
    "            b_preds = model(x).squeeze(1)\r\n",
    "\r\n",
    "            b_preds = val_aug_dataloader.dataset.converge_aug_inference(b_preds.detach().cpu())\r\n",
    "            \r\n",
    "            preds = torch.cat([preds, b_preds], dim = 0)\r\n",
    "            labels = torch.cat([labels, targets.detach()], dim = 0)\r\n",
    "            \r\n",
    "epoch_loss = criterion(preds,labels)\r\n",
    "run[\"dev/aug_loss\"].log(epoch_loss)\r\n",
    "\r\n",
    "jac = jaccard_coeff(preds,labels)\r\n",
    "run[\"dev/aug_jaccard\"].log(jac)\r\n",
    "\r\n",
    "if VAL_WATERSHED:\r\n",
    "    preds_ws = post_watershed(preds)\r\n",
    "    jac_w = jaccard_coeff(preds_ws,labels)\r\n",
    "    run[\"dev/jaccard_ws\"].log(jac_w)    \r\n",
    "\r\n",
    "print('Augmented Validation: ', epoch_loss, jac)\r\n",
    "valid(model,val_dataloader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from skimage.segmentation import watershed\r\n",
    "from skimage.feature import peak_local_max\r\n",
    "\r\n",
    "from scipy import ndimage as ndi\r\n",
    "\r\n",
    "from multiprocessing import Pool\r\n",
    "\r\n",
    "N_WORKERS = 10\r\n",
    "\r\n",
    "def w_watershed(img):\r\n",
    "\r\n",
    "    distance = ndi.distance_transform_edt(img)\r\n",
    "\r\n",
    "    coords = peak_local_max(distance, footprint=np.ones((3, 3)),labels=img)\r\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\r\n",
    "    mask[tuple(coords.T)] = True\r\n",
    "    markers, _ = ndi.label(mask)\r\n",
    "    p = watershed(-distance, markers, mask=img)\r\n",
    "\r\n",
    "    return p\r\n",
    "\r\n",
    "def post_watershed(x):\r\n",
    "\r\n",
    "    x = torch.nn.Sigmoid()(x)\r\n",
    "    x = (x > 0.5) * 1\r\n",
    "\r\n",
    "    x = x.numpy().astype(np.int32)\r\n",
    "    \r\n",
    "    pool = Pool(processes=N_WORKERS)\r\n",
    "\r\n",
    "    l = []\r\n",
    "    for s, result in enumerate(pool.imap(func=w_watershed, iterable=x)):\r\n",
    "        print(s)\r\n",
    "        l.append(result)\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    l = []\r\n",
    "    for s, img in enumerate(x):\r\n",
    "        print(s)\r\n",
    "        l.append(w_watershed(img))\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    return torch.tensor(l)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VAL_WATERSHED = True\r\n",
    "valid(model,val_dataloader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('flood': conda)"
  },
  "interpreter": {
   "hash": "fc4cbb02288c0c4c9f4deb429c34e5d9e72ec802a611d80aa17a720de2d4ef43"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}